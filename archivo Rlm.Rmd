---
title: "Trabajo Final"
author: "jhonatan_castañeda"
date: "2 de agosto de 2015"
output: html_document
---

---

### Introducción

El presente documento genera un 
__reporte__
automático utilizano:

* R
* Markdown
    + __Rmarkdown__

### Descripción información 

Iniciamos cargando los archivos que contienen las varibles a utilizar, y encontrando sus dimenciones:

```{r,echo=TRUE,eval=TRUE}
options(warn=-1)
library(readxl)
library(DT)
library(ggplot2)


data1 <- read_excel("poblacion1.xlsx",sheet=1,col_names = TRUE,na = "")
View(data1)
str(data1)
dim(data1)

data2 <- read_excel("poblacion2.xlsx",sheet=1,col_names = TRUE,na = "")
View(data2)
str(data2)
dim(data2)

```

Analizando la información disponemos de `r nrow(data2)` observaciones de `r ncol(data1)+ncol(data2)-1` variables.
Las cuales se deben poner en una sola data a la que llamaremos poblacion de la siguiente forma:

```{r,echo=TRUE,eval=TRUE}
poblacion <- merge(x = data1 ,y = data2, by = "identificador", suffixes = c("","")) 
View(poblacion)
str(poblacion)
names(poblacion)
dim(poblacion)

```

Ahora se quiere crear un código que identifique la clase de cada variable y genere diagramas de cajas para variables continuas y diagramas de barras para variables discretas, lo cual se logra de la siguiente manera:

Nota: apply(poblacion,2,class) deberia funcionar, pero no lo hace, no encuentro el problema...

```{r,echo=TRUE,eval=TRUE}

cl <- c(1:ncol(poblacion))


for (i in 1:ncol(poblacion)){
  cl[i] <- class(poblacion[,i])
}

cl


for(i in 1:ncol(poblacion)) 
  {
  if(is.numeric(poblacion[,i]))
    {
    boxplot(poblacion[,i], xlab = "", ylab=names(poblacion)[i], main=paste("Diag cajas de",names(poblacion)[i]),
            col="steelblue", border="gray1") 
  }
  if(is.character(poblacion[,i]))
    {
    barplot(table(poblacion[,i]), xlab = names(poblacion)[i], ylab="Frecuencia", main="Diagrama de barras",
            col="steelblue", border="gray1")  
  }
}

```


Nota: En i igual a 1 no se tiene ningun sentido ya que son los codigos unicos, por tanto podriamos usar for(i in 2:ncol(poblacion))


Ahora queremos crear un código que calcule automáticamente el mínimo, media, máximo, desviación estándar, primer cuartil de cada variable numérica y la frecuencia en el caso de variables categóricas, lo que se tiene con:

```{r,echo=TRUE,eval=TRUE}
for(i in 1:ncol(poblacion))
  {
  if(is.numeric(poblacion[,i]))
    {
    print( paste("Para ",names(poblacion)[i],"   El minimo es de ",min(poblacion[,i]),
    "     El maximo es de ",max(poblacion[,i]),"    La media es de ",mean(poblacion[,i]),
    "     La desviacion estandar es de ", sd(poblacion[,i]),"    Y el primer cuartil es ",
    quantile(poblacion[,i], probs = seq(0, 1, 0.25), na.rm = FALSE)))
  }
  if(is.character(poblacion[,i]))
    {
    print(paste("Las frecuencias de ",names(poblacion)[i],"son representadas así:"))
    print(table(poblacion[,i]))
  }
}

```


Nota: En i igual a 1 no se tiene ningun sentido ya que son los codigos unicos, por tanto podriamos usar #for(i in 2:ncol(poblacion))



El calculo de la correlación entre la variable dependiente poblacion y cada una de las
variables explicativas (numéricas) se obtiene de:


```{r,echo=TRUE,eval=TRUE}
co <- c(1:ncol(poblacion))

for(i in 1:ncol(poblacion))
  {
  if(is.numeric(poblacion[,i]))
    {
    co[i]<-cor(poblacion$poblacion,poblacion[,i])
    
  }
  if(is.character(poblacion[,i]))
  {
    co[i]<-0
  }
}
co
```

Nota:en i igual a 1 no se tiene ningun sentido ya que son los codigos unicos, en i igual a 2 se tiene a poblacion por tanto podriamos usar for(i in 3:ncol(poblacion))

Considerando la variable categórica serv.bas.compl con una confiabilidad del 90%, ¿Pue-
de asumirse que la media de la variable poblacion en el grupo serv.bas.compl: SI
es distinta a la media del grupo serv.bas.compl: NO ?

para esto se tiene que transformar los datos, de "si" y "no" a 1 y 0 respectivamente, los datos con "si y "no" no funcionavan bien, por tanto se tiene que 0 es no y 1 es si, donde x es un vector con no en cada entrada y y representa la variable serv.bas.compl, la prueba dice que:


```{r,echo=TRUE,eval=TRUE}

x <- c(1:dim(poblacion)[1])
y <- c(1:dim(poblacion)[1])

for(i in 1: dim(poblacion)[1])
{
  
  x[i] <- 0
  
  if(poblacion[i,10]=="SI")
  {
  
  y[i] <- 1
  
  }
  else
  {
    y[i] <- 0
  }
  
  }
  
  
  
t.test(x,y, alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.90)

```



Considerando los calculos anteriores generar el modelo de regresion lineal multiple que
mejor se ajuste a los datos se puede hacer mirando las ceorrelaciones que existen entre la variable poblacion y las demas, por tanto se obtiene que las mejores opciones son:

entonses se tiene que las variables para la regresion serian:

```{r,echo=TRUE,eval=TRUE}

k=0
for (i in 1:ncol(poblacion))
{
  
  if (names(poblacion)[i]=="poblacion")
  {
    
  }
  else
  {
    
  if (abs(co[i]) > 0.35)
  {
    k=k+1
  }
  }
  }
k

nm <- c(1:k)
num <- c(1:k)

j=1

for (i in 1:ncol(poblacion))
{
  
  if (names(poblacion)[i]=="poblacion")
  {
    
  }
  else
  {
    
    if (abs(co[i]) > 0.35)
    {
      num[j] <- i
      nm[j] <- names(poblacion)[i]
      j=j+1
    }
  }
}

nm


g <- ggplot(data = NULL, aes(x=poblacion[,2], y=poblacion[,num[1]]))
g + geom_point() + geom_smooth(method="lm")


g <- ggplot(data = NULL, aes(x=poblacion[,2], y=poblacion[,num[2]]))
g + geom_point() + geom_smooth(method="lm")



```


Por ende la regresion seria:

```{r,echo=TRUE,eval=TRUE}

reg <- lm(poblacion[,2]~poblacion[,num[1]]+poblacion[,num[2]], NULL)
summary(reg)

```

es decir nuestro modelo resultante estaría dado por la expresión
$$\hat{`r names(poblacion)[2]`} = `r reg$coefficients[1]` + `r reg$coefficients[2]`  \hat{`r names(poblacion)[num[1]]`}+ `r reg$coefficients[3]`  \hat{`r names(poblacion)[num[2]]`}$$

. La interpretacion de los coeficientes obtenidos es que:
Si `r names(poblacion)[num[1]]` se incrementa en una unidad, sabiendo que son codigos y se los ha hecho de tal forma que nos de asi, entonces `r names(poblacion)[2]`
`r tex <-"aumenta"; if(reg$coefficients[2]<0) (tex<-"disminuye");tex` en promedio `r abs(reg$coefficients[2])`
unidades._

Y si `r names(poblacion)[num[2]]` se incrementa en una unidad, entonces `r names(poblacion)[2]`
`r tex <-"aumenta"; if(reg$coefficients[3]<0) (tex<-"disminuye");tex` en promedio `r abs(reg$coefficients[2])`
unidades._


Se puede ver que la segunda variable no es significativa, pero si no se la usa solamente estariamos comparando con una variable, lo que aria el caso de regresion simple.
Por otro lado el uso de una variable que no son mas que codigos no es recomendable, pero la usare por lo expuesto en el documento rml.R



El modelo de regresión lineal obtenido explica el `r paste(100*summary(reg)$r.squared,"%")` de la variabilidad total._


Analizando __LOS VALORES DE T__ tenemos los siguientes resultados:

Para $: \beta_1$ es:
```{r,echo=TRUE,eval=TRUE}
abs(summary(reg)$coefficients[[7]])

```
Como $t=`r abs(summary(reg)$coefficients[[7]])`$ es `r tex<-"menor"; if(abs(summary(reg)$coefficients[[7]])>qt(0.975,(nrow(poblacion)-2))) tex<-"mayor"; tex` que $t_{`r (nrow(poblacion)-2)`}(\frac{\alpha}{2})= `r qt(0.95,(nrow(poblacion)-2))`$
`r tex<-"no rechazo"; if(abs(summary(reg)$coefficients[[7]])>qt(0.95,(nrow(poblacion)-2))) tex<-"rechazo"; tex`
$H_0: \beta_1=0$.

Para $: \beta_2$ es:
```{r,echo=TRUE,eval=TRUE}
abs(summary(reg)$coefficients[[8]])


```
Como $t=`r abs(summary(reg)$coefficients[[8]])`$ es `r tex<-"menor"; if(abs(summary(reg)$coefficients[[8]])>qt(0.975,(nrow(poblacion)-2))) tex<-"mayor"; tex` que $t_{`r (nrow(poblacion)-2)`}(\frac{\alpha}{2})= `r qt(0.95,(nrow(poblacion)-2))`$
`r tex<-"no rechazo"; if(abs(summary(reg)$coefficients[[8]])>qt(0.95,(nrow(poblacion)-2))) tex<-"rechazo"; tex`
$H_0: \beta_2=0$.



Para $: \beta_3$ es:
```{r,echo=TRUE,eval=TRUE}
abs(summary(reg)$coefficients[[9]])


```
Como $t=`r abs(summary(reg)$coefficients[[9]])`$ es `r tex<-"menor"; if(abs(summary(reg)$coefficients[[9]])>qt(0.975,(nrow(poblacion)-2))) tex<-"mayor"; tex` que $t_{`r (nrow(poblacion)-2)`}(\frac{\alpha}{2})= `r qt(0.95,(nrow(poblacion)-2))`$
`r tex<-"no rechazo"; if(abs(summary(reg)$coefficients[[9]])>qt(0.95,(nrow(poblacion)-2))) tex<-"rechazo"; tex`
$H_0: \beta_2=0$.



Realizando la tabla __ANOVA__ tenemos los siguientes resultados:
```{r,echo=TRUE,eval=TRUE}
anova <- aov(reg)
summary(anova)[[1]]
```

Como $F=`r abs(summary(anova)[[1]][1,4])`$ es `r tex<-"menor"; if(abs(summary(anova)[[1]][1,4])>qf(0.95,1,(nrow(poblacion)-2))) tex<-"mayor"; tex` que $F_{1,`r (nrow(poblacion)-2)`}(\frac{\alpha}{2})= `r qf(0.95,1,(nrow(poblacion)-2))`$
`r tex<-"no rechazo"; if(abs(summary(anova)[[1]][1,4])>qf(0.95,1,(nrow(poblacion)-2))) tex<-"rechazo"; tex`
$H_0:$ el modelo no es significante.


Para el analisis de los Residuos se tiene que las graficas son de gran ayuda, para esto se analiza:

```{r}
    residuo <- reg[["residuals"]]
    prediccion <- reg[["fitted.values"]]
    data2 <- data.frame(poblacion, prediccion,residuo)
    datatable(data2,filter="top", options = list(
    searching = TRUE,
    pageLength = 5,
    lengthMenu = c(5, 10, 15)))
 
```

```{r, fig.align="center",fig.width=5,fig.height=4}
    hist(residuo,15)
    mean(residuo)
    qqnorm(residuo)
    qqline(residuo,col="red")
    plot(residuo,prediccion)
    plot(residuo,poblacion[,num[1]])
    plot(residuo,poblacion[,num[2]])
    
```

Lo cual nos mestra claramente datos atipicos en la regresion, los cuales se deben buscar y eliminar para mejorar la regresion.